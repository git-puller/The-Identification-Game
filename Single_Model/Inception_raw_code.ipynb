{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This cell will help us plot the convergence of the model in real time\n",
    "!pip install pycm livelossplot\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# This cell performs all the imports that we will need in this coursework\n",
    "from sklearn.metrics import accuracy_score # this allows us to evaluate our model at every iteration\n",
    "from sklearn.metrics import f1_score # this allows us to evaluate our validation accuracy\n",
    "from sklearn.model_selection import StratifiedShuffleSplit # this allows us to create a random validation split\n",
    "\n",
    "# These imports help plot the convergence and create the confusion matrix\n",
    "from livelossplot import PlotLosses\n",
    "from pycm import *\n",
    "\n",
    "# These imports help us create models and datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# This allows me to create my own custom dataset\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "# This allows me to import pretrained models for transfer learning\n",
    "import torchvision.models as torchmodels\n",
    "\n",
    "# This allows me to do a number of transforms for data augmentation later on\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize, RandomApply, RandomChoice, RandomRotation, RandomCrop, RandomHorizontalFlip, RandomAffine, ToPILImage\n",
    "\n",
    "# These imports help us write the submission file\n",
    "import json, csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions sets up all our random seeds so that the results will be reproducible\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Enable hardware acceleration\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "transform_vgg16_train = Compose([\n",
    "    # ToPILImage(),\n",
    "    Resize(224),\n",
    "    RandomApply([RandomChoice([RandomCrop(size=[224, 224], padding=10), \n",
    "                               RandomAffine(0, translate=(0.01, 0.01))])]), # choose one or 0 transforms that make the image smaller\n",
    "    RandomApply([RandomChoice([RandomHorizontalFlip(), RandomRotation(10)])]), # choose one or zero transforms to rotate or flip the image\n",
    "    ToTensor(),\n",
    "    Normalize(mean=means, std=stds), \n",
    "]) ##Compose different transforms together. PIL is Python Imaging Library useful for opening, manipulating, and saving many different image file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "seed = 42\n",
    "lr = 1e-2\n",
    "momentum = 0.5\n",
    "batch_size = 36 # Mini-batch mode\n",
    "test_batch_size = 500\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset from the default folder\n",
    "# Tiny-imagenet-200\n",
    "my_data = training = ImageFolder(\"../input/acse-miniproject/train/\",transform = transform_vgg16_train ) #/content/gdrive/My Drive/ACSE4-ML-miniproject/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageFolder(\"../input/acse-miniproject/test/\", transform_vgg16_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation and training\n",
    "train_size = int(0.9 * len(my_data))\n",
    "validation_size = len(my_data) - train_size\n",
    "train_dataset, validation_dataset = random_split(my_data, [train_size, validation_size])\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First import resnet from models, it is pretrained on imagenet and we will keep those weights to detect features\n",
    "# # vgg13 = torchmodels.vgg13(pretrained=True)\n",
    "# vgg11 = torchmodels.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 299\n",
    "feature_extract = True\n",
    "model_ft = torchmodels.inception_v3(pretrained=True)\n",
    "for param in model_ft.parameters():\n",
    "        param.requiresgrad = False\n",
    "\n",
    "model_ft.AuxLogits.fc = nn.Linear(768, 200)\n",
    "model_ft.fc = nn.Linear(2048,200)\n",
    "model_ft.aux_logits = False\n",
    "\n",
    "\n",
    "        \n",
    "# set_parameter_requires_grad(model_ft, feature_extract)\n",
    "# # Handle the auxilary net\n",
    "# num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "# model_ft.AuxLogits.fc = nn.Linear(num_ftrs, 200)\n",
    "#         # Handle the primary net\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs,200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=200, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = training = ImageFolder(\"../input/acse-miniproject/train/\",transform = data_transforms ) #/content/gdrive/My Drive/ACSE4-ML-miniproject/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageFolder(\"../input/acse-miniproject/test/\", test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze the weights in the earlier layers:\n",
    "# for param in vgg16.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# print(vgg16)\n",
    "\n",
    "# vgg16 has 16 layers with the last 4 are fc layers\n",
    "# unfreeze the last layer so it learns on our dataset\n",
    "# layer_num = 0\n",
    "# for child in vgg11.children():\n",
    "#   layer_num += 1\n",
    "#   if layer_num < 11:\n",
    "#       for param in child.parameters():\n",
    "#           param.requires_grad = False\n",
    "# # vgg16.fc = nn.Linear(num_ftrs, 10) # change number of output classes\n",
    "# num_classes = 200\n",
    "# num_ftrs = vgg11.classifier[6].in_features\n",
    "# vgg11.classifier[6] = nn.Linear(num_ftrs,num_classes)# change number of output classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        a2 = model(X.view(-1, 3, 224, 224)) # when transferring vgg later on, it takes 224x224 inputs rather than 32x32\n",
    "        loss = criterion(a2, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*X.size(0)\n",
    "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
    "        optimizer.step()\n",
    "         \n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
    "def validate(model, criterion, data_loader):\n",
    "  model.eval()\n",
    "  validation_loss, validation_accuracy = 0., 0.\n",
    "  for X, y in data_loader:\n",
    "    with torch.no_grad():\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      a2 = model(X.view(-1, 3, 224, 224)) # when transferring vgg later on, it takes 224x224 inputs rather than 32x32\n",
    "      loss = criterion(a2, y)\n",
    "      validation_loss += loss*X.size(0)\n",
    "      y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "      validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
    "      \n",
    "  return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "  model.eval()\n",
    "  ys, y_preds = [], []\n",
    "  for X, y in data_loader:\n",
    "    with torch.no_grad():\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      a2 = model(X.view(-1, 3, 224, 224)) # when transferring vgg later on, it takes 224x224 inputs rather than 64x64\n",
    "      y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "      ys.append(y.cpu().numpy())\n",
    "      y_preds.append(y_pred.cpu().numpy())\n",
    "            \n",
    "  return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)\n",
    "\n",
    "def predict(model, data_loader):\n",
    "  model.eval()\n",
    "  files, y_preds = [], []\n",
    "  for X, y, z in data_loader:\n",
    "      with torch.no_grad():\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        a2 = model(X.view(-1, 3, 224, 224)) # when transferring vgg later on, it takes 224x224 inputs rather than 64x64\n",
    "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "        y_preds.append(y_pred.cpu().numpy())\n",
    "        files.append(z)\n",
    "            \n",
    "  return np.concatenate(y_preds, 0), np.concatenate(files, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.570, max:    0.836, cur:    0.836)\n",
      "\tvalidation       \t (min:    0.701, max:    0.710, cur:    0.701)\n",
      "log loss\n",
      "\ttraining         \t (min:    0.629, max:    1.998, cur:    0.629)\n",
      "\tvalidation       \t (min:    1.189, max:    1.271, cur:    1.271)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = vgg11.to(device)\n",
    "model = model_ft.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(6):\n",
    "    logs = {}\n",
    "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "    \n",
    "    logs['' + 'log loss'] = train_loss.item()\n",
    "    logs['' + 'accuracy'] = train_accuracy.item()\n",
    "    \n",
    "    validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "   \n",
    "    logs['val_' + 'log loss'] = validation_loss.item()\n",
    "    logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "    \n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = evaluate(model, validation_loader)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions, my_files = predict(resnet2, test_loader)\n",
    "\n",
    "my_files_clean = [my_files[i][38:] for i in range(len(my_files))]\n",
    "\n",
    "with open('submission.csv', 'w', encoding=\"ISO-8859-1\", newline='') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow((\"Filename\", \"Label\"))\n",
    "    wr.writerows(zip(my_files_clean,my_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the augmented model:\n",
    "model_save_name = 'GoogleNet_inception_v3.pth'\n",
    "path = F\"./{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
